{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "USMLProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Starting Pyspark Session "
      ],
      "metadata": {
        "id": "0wozZU3wIgAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install pyspark\n",
        "from pyspark.sql import SparkSession, SQLContext\n",
        "sparkSess = SparkSession.builder.appName(\"Association Rule Mining\").config(\"spark.executor.memory\", \"50g\").config('spark.driver.memory','50g').config(\"spark.memory.fraction\", 0.9).getOrCreate()"
      ],
      "metadata": {
        "id": "ZcPy7GlPV9As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To link GCP bucket to Colab"
      ],
      "metadata": {
        "id": "FOLjo0GKBrht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import auth\n",
        "# !echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "# !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "# !apt -qq update\n",
        "# !apt -qq install gcsfuse\n",
        "# !mkdir Data\n",
        "!gcsfuse --implicit-dirs usml-data Data"
      ],
      "metadata": {
        "id": "xR6DAAdeq2pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "n8bpbXGSIpGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To combine all CSV files and store them in spark Dataframe**"
      ],
      "metadata": {
        "id": "bfb6m88JB774"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataPath = '/content/Data/Data/*/*/*-street.csv'\n",
        "data = sparkSess.read.csv(dataPath, header = True, sep = \",\")"
      ],
      "metadata": {
        "id": "HUmp3St-cZB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataorg = data"
      ],
      "metadata": {
        "id": "Y7oL0cyacpI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop('Crime ID', 'Latitude', 'Longitude','LSOA code','Context','Reported by')"
      ],
      "metadata": {
        "id": "ZKM4lt27va0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import split\n",
        "data = data.withColumn('Year', split(data['Month'], '-').getItem(0))\n",
        "data = data.withColumn('Month', split(data['Month'], '-').getItem(1))"
      ],
      "metadata": {
        "id": "cEXdaIOe2ITy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.filter(data['Crime type'] != 'Anti-social behaviour')\n",
        "data = data.filter(data['LSOA name'].isNotNull())"
      ],
      "metadata": {
        "id": "ImtEvkL_4M_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace\n",
        "data = data.withColumn('Location', regexp_replace('Location','On or near',''))\n",
        "data = data.withColumn('LSOA name',regexp_replace('LSOA name', ' [0-9]{3}\\w', ''))"
      ],
      "metadata": {
        "id": "Z3OG-fl6KxIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import array_distinct, array\n",
        "data = data.withColumn('itemsets', array(data['Falls Within'], data['Location'], data['Crime type'], data['Last outcome category']))"
      ],
      "metadata": {
        "id": "su6IEKnX3muF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data.describe().show()"
      ],
      "metadata": {
        "id": "jVLwFjzQ4b9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "5U4SCEBLGpVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import calendar\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from plotnine import ggplot, geoms"
      ],
      "metadata": {
        "id": "_KS9YNvfHMoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Incidents of Reported Street Crime (Dec 2010 - Feb 2022)**"
      ],
      "metadata": {
        "id": "4B5T0DQBHwJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25, 5))\n",
        "crime_over_time = data\\\n",
        "                  .groupBy([\"Month\", \"Year\"])\\\n",
        "                  .count()\\\n",
        "                  .toPandas()\n",
        "months = map(lambda x: calendar.month_abbr[x], range(1, 13))\n",
        "crime_time_series = crime_over_time\\\n",
        "                    .set_index([\"Year\", \"Month\"])\\\n",
        "                    .sort_index()\\\n",
        "                    .squeeze()\n",
        "plot = crime_time_series.plot(kind = \"line\", color=\"b\", title = \"Incidents of Reported Street Crime (Dec 2010 - Feb 2022)\")\n",
        "plot.set_xticks(range(0, len(crime_time_series.index)))\n",
        "plot.set_xticklabels(list(crime_time_series.index), rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ODmuNtTBCce0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 20 total Reported Crime Type and Outcome combination**"
      ],
      "metadata": {
        "id": "pyEZVZXaISsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "outcome_counts = data\\\n",
        "              .groupBy([\"Crime type\", \"Last outcome category\"])\\\n",
        "              .count()\\\n",
        "              .sort(F.col(\"count\").desc())\\\n",
        "              .toPandas()\n",
        "outcome_counts_series = outcome_counts\\\n",
        "                        .set_index([\"Crime type\", \"Last outcome category\"])\\\n",
        "                        .squeeze()\\\n",
        "                        .apply(lambda x: x*100/outcome_counts[\"count\"].sum())\\\n",
        "                        .head(20)\n",
        "index = [str(x) + \" -> \" + str(y) for x, y in outcome_counts_series.index]\n",
        "plot = sns.barplot(x = outcome_counts_series.values, y = index, color='b')\n",
        "    \n",
        "plot.set_title('% Total Reported Crime Type and Outcome combination (Dec 2010 - Feb 2022)')\n",
        "plot.set_xlabel('% of Reported Crimes') \n",
        "plot.set_ylabel('Crime Type -> Outcome')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UaYueqRVQSvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting Fpgrowth Algorithm and extracting rules"
      ],
      "metadata": {
        "id": "EjEhW0n3Cunn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating List of Itemsets**"
      ],
      "metadata": {
        "id": "snnCK5TjI7Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "itemsets = data.drop_duplicates(['itemsets']).select('itemsets')"
      ],
      "metadata": {
        "id": "Ljz7OPZxI1ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.fpm import FPGrowth\n",
        "fpgrowth = FPGrowth(itemsCol = 'itemsets',minSupport = 0.001, minConfidence = 0.02)\n",
        "model = fpgrowth.fit(itemsets)"
      ],
      "metadata": {
        "id": "EZLd31Q93muH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "association_rules = model.associationRules"
      ],
      "metadata": {
        "id": "Eik2jrFb5aZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# association_rules.count()"
      ],
      "metadata": {
        "id": "gGxyppa_3muI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rules = association_rules[((association_rules['confidence'] > 0.2)) & (association_rules['lift'] > 1)].toPandas()"
      ],
      "metadata": {
        "id": "2oZ2d6l83muI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rules.sort_values(by = 'confidence',ascending=False)"
      ],
      "metadata": {
        "id": "62ACBHA3Pu38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequentItems = model.freqItemsets.toPandas()"
      ],
      "metadata": {
        "id": "i4XB6Q9rjTlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating Interest**"
      ],
      "metadata": {
        "id": "OvK1Wrx0D2iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "itemsetsCount = itemsets.count()\n",
        "sum = 0\n",
        "mainList=[]\n",
        "for i,conseq in rules.iterrows():\n",
        "  # print(conseq['consequent'])\n",
        "  lis=[]\n",
        "  for index, row in frequentItems.iterrows():\n",
        "    if(all(elem in row['items'] for elem in conseq['consequent'])):\n",
        "      lis.append(row['freq'])\n",
        "  mainList.append([conseq['antecedent'], conseq['consequent'], conseq['support'], conseq['confidence'], conseq['lift'],conseq['confidence']- max(lis)/itemsetsCount])"
      ],
      "metadata": {
        "id": "ex0CMe77qR0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Rules"
      ],
      "metadata": {
        "id": "zylIC_SOEkKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame (mainList, columns = ['antecedent','consequent','support','confidence','lift','interest'])"
      ],
      "metadata": {
        "id": "-bPXlZ0dXU-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(by = 'confidence',ascending=False)#.to_csv('rules.csv')"
      ],
      "metadata": {
        "id": "N9Hz50rDYYCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import networkx as nx  \n",
        "graph_1 = nx.DiGraph()\n",
        "cm=[]\n",
        "N = 50\n",
        "clrs = np.random.rand(N)    \n",
        "strs=['R0', 'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7', 'R8', 'R9', 'R10', 'R11']   "
      ],
      "metadata": {
        "id": "kJhy6AFV1MJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (12):      \n",
        "  graph_1.add_nodes_from([\"R\"+str(i)]) \n",
        "  for a in df['antecedent'][i]:         \n",
        "      graph_1.add_nodes_from([a])\n",
        "      graph_1.add_edge(a, \"R\"+str(i), color=clrs[i] , weight = 2)\n",
        "  for c in df['consequent'][i]:\n",
        "          graph_1.add_nodes_from([c])\n",
        "          graph_1.add_edge(\"R\"+str(i), c, color=clrs[i],  weight=2)"
      ],
      "metadata": {
        "id": "x7Is7PTfF_3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for node in graph_1:\n",
        "      found_a_string = False\n",
        "      for item in strs: \n",
        "          if node==item:\n",
        "              found_a_string = True\n",
        "      if found_a_string:\n",
        "          cm.append('yellow')\n",
        "      else:\n",
        "          cm.append('green')"
      ],
      "metadata": {
        "id": "F8lfrCa5F9YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = graph_1.edges()\n",
        "clrs = [graph_1[u][v]['color'] for u,v in edges]\n",
        "weights = [graph_1[u][v]['weight'] for u,v in edges]\n",
        "plt.figure(figsize=(8, 8))\n",
        "pos = nx.spring_layout(graph_1, k=16, scale=1)\n",
        "nx.draw(graph_1, pos, edgelist=edges, node_color = cm, edge_color=clrs, width=weights, font_size=8, with_labels=False) "
      ],
      "metadata": {
        "id": "MPx3Qq4aF7K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in pos: \n",
        "          pos[p][1] += 0.1\n",
        "          \n",
        "nx.draw_networkx_labels(graph_1, pos,font_size=8)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8AKcs_OAF3kT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}